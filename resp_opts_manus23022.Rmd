---
title             : "Inclusive Response Options Expand Gender Categorization But Do Not Reduce Categorical Perception of Gender"
shorttitle        : "Rsponse options and gender categorization"

author: 
  - name          : "Elli van Berlekom"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Albanovägen 12"
    email         : "elli.vanberlekom@psychology.su.se"
    role:         # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
      - "Conceptualization"
      - "Data collection"
      - "Data analysis"
      - "Writing - Original Draft Preparation"
      - "Writing - Review & Editing"
  - name          : "Stefan Wiens"
    affiliation   : "1"
    role:
      - "Data analysis"
      - "Writing - Review & Editing"
  - name          : "Anna Lindqvist"
    affiliation   : "2"
    role:
      - "Conceptualization"
      - "Writing - Review & Editing"
  - name          : "Marie Gustavsson Sendén"
    affiliation   : "1"
    role:
      - "Conceptualization"
      - "Writing - Review & Editing"



affiliation:
  - id            : "1"
    institution   : "Stockholm University"
  - id            : "2"
    institution   : "Lund University"

authornote: |
  Data & scripts are available at figshare. The authors declare no conflict of interest.

abstract: | 
 Gender categorization - the process through which gender categories are applied to others - is studied almost exclusively measure categorization by allowing participants to respond in terms of woman and men only. This does not capture the diversity of gender which is a problem because it may be inaccurate and it may be harmful to gender diverse individuals. This study (N = 120) investigated how more inclusive response options affected gender categorization in terms of options chosen and categorical perception. Participants were more likely to categorize gender beyond the binary when provided with explicit response options, such as "non-binary" and "I don't know". Additional responses did not affect categorical perception. The study highlights the importance of careful consideration of response options in gender categorization research. 
 
 *Problem statement can be made much clearer*

  
keywords          : "Gender diversity, Gender categorization, Transgender, Measurement"
wordcount         : "3969"

bibliography      : "r-references.bib"

floatsintext      : no
linenumbers       : no
draft             : no
mask              : no

figurelist        : no
tablelist         : no
footnotelist      : no

header-includes:
  - |
    \makeatletter
    \renewcommand{\paragraph}{\@startsection{paragraph}{4}{\parindent}%
      {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
      {-1em}%
      {\normalfont\normalsize\bfseries\typesectitle}}
    
    \renewcommand{\subparagraph}[1]{\@startsection{subparagraph}{5}{1em}%
      {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
      {-\z@\relax}%
      {\normalfont\normalsize\bfseries\itshape\hspace{\parindent}{#1}\textit{\addperi}}{\relax}}
    \makeatother

csl               : "`r system.file('rmd', 'apa7.csl', package = 'papaja')`"
documentclass     : "apa7"
output            : papaja::apa6_pdf
always_allow_html: true
---

```{r setup,warning = FALSE, message = FALSE}
library("papaja")
library(brms)
library(tidyverse)
citations <- r_refs("r-references.bib")

library(brms)
library(tidyverse)
source("src/functions.r")
d  <- read_and_clean("data/cat2stduy1_data.csv") %>% 
  mutate(fem = 100-masc) 

```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

Accuracy is key when measuring constructs in psychological research. One area where there is a lack of nuance is in the use of binary  response options for gender (i.e. "woman" and "man"), which fails to capture the complex and fluid nature of gender/sex [@hyde_future_2018; @lindqvist_what_2020]. Surveys and interviews of transgender and gender diverse (TGD) individuals suggest that many people experience gender as a fluid category, which can change over time and which is not easily defined [@richards_non-binary_2016]. This means that someone's appearance alone is not always a reliable indicator of gender. Additionally TGD individuals experience invisibility, due to the assumption that there are only two genders and that gender should be visible from someone’s face [@ansara_methodologies_2014]. It is important that research takes this lived reality into account when designing measures of gender categorization to avoid perpetuating this marginalization.

Although researchers have begun offering participants more flexible options to define their own gender [@lindqvist_what_2020; @saperstein_categorical_2021], such as additional categories or free text responses, studies still predominantly use binary gender options when categorizing participants. Understanding of how response options affect gender categorization remains limited. Therefore, the current study aims to test how non-binary alternatives affect gender categorization.

A pioneering approach to conceptualizing gender was the BSRI which challenged the dichotomous and binary conceptualizations of gender [@bem_measurement_1974]. The BSRI measured femininity and masculinity as separate traits, finding that many individuals exhibit a mixture of feminine and masculine traits. The BSRI has mostly been used to measure self-reports of gender as a trait. More recently, several guides have been developed that recommend the use of open free text options or multiple options (e.g., woman, man, other, non-binary). when asking participants to indicate their gender (see for example Lindqvist et al., 2020). Although this practice is still far from the norm, it is becoming increasingly commonplace for researchers to measure gender of participants in this open-ended way [@carleton_assessing_2022; @cronin_younger_2022; @dagostino_organizational_2022; @gottgens_impact_2022]

In contrast, the research on how people perceive and categorize the gender of others still almost exclusively treats gender as a binary category. Researchers in this field have explored the speed and automaticity of gender perception in faces, as well as which facial features are associated with specific gender categories, such as women and men [e.g. @mogilski_relative_2018] . Generally, the findings have been used to argue that gender is rapidly and automatically categorized [@habibi_spontaneous_2012; @jung_automaticity_2019], with facial features such as skin smoothness, jawline, and hair length used to determine gender identity. Lastly, studies in this field have indicated that people perceive faces categorically [@campanella_categorical_2001]. In other words, that faces, even when manipulated to vary on a continuum from feminine to masculine were still perceived as belonging to the categories women or man. However, these studies typically do reflect the diverse nature of gender or consider alternative response options.

Instead, gender categorization is most often measured through a forced-choice task in which participants are forced to indicate either "female" or "male" when presented with a face [see for example @campanella_categorical_2001; @cloutier_perceptual_2005; @webster_adaptation_2004; @zhao_own-_2008]. A slightly different approach asks participants to rate faces on a gender gradation as a quality, often using "feminine" and "masculine" as endpoints on a single gradation [@dascenzo_imagining_2014]. Only in some rare cases are masculinity and femininity measured using different gradations for femininity and masculinity [e.g. @wittlin_about_2018]. Despite some variations therefore, the literature overwhelmingly presents gender as a binary in studies of gender categorization of others.

*p. 5 mentions four “reasons researchers should be concerned about measuring gender categorization with binary options only”. What is the difference between (1) and (2) (isn’t the minority stress what makes the norm harmful?); and what is the difference between (3) and (4) (isn’t the reduction in variation due to the skewing?)*


There are several reasons researchers should be concerned about measuring gender categorization with binary options only. One is that it does not accurately reflect the diversity of gender [@hyde_future_2018]. Researchers who engage in this practice are perpetuating the harmful norm that gender is binary. *This furthers the idea of gender as binary, causing indirect harm*. *In a more direct way, you are undermining participants* may directly cause minority stress to TGD individuals, who are once again faced with a situation where they are not considered. There may also be two sources of measurement error stemming from binary response options. By creating a binary out a more varying dimension, researchers may be missing an important source of variation, similar to how measurement of age as only "young" or "old" would miss a large source of variation. Secondly, by reinforcing a binary gender worldview, researchers may actually be biasing participants towards that worldview, skewing the results. *can be clarified, skewing the results how?*

Here we report two studies which attempted to address these two potential sources of error. Study 1 investigates whether people use response options beyond the binary when they are able (Research Question 1) and how this influences categorizations of women and men (Research Question 2). Study 2 investigates whether perception of gender is accentuated towards the extremes (Research Question 3), and whether with a focus on the categorical perception of gender (Research Question 3).

# Study 1

Study 1 was based on common practices for self-identification of gender. One common practice is to include a third option gender option, such as "non-binary" or "other". Another common practice is to give people an open text box in which they may type in whatever they like [@lindqvist_what_2020; @saperstein_categorical_2021]. Therefore, Study 1 compared the standard binary response options to two alternatives: a third gender option (such as 'non-binary' or 'other') and an open text box for participants to type in their gender. An important difference between self-categorization and the categorization of others is that most people know their own gender, whereas the gender of others cannot always be known from appearance [@richards_non-binary_2016]. To account for this, we also gave participants the ability to state that gender was unknown.

# Method

## Participants

```{r}
# Get subjects information
subs <- d %>%
  filter(condition == "ft" | condition == "xb" | condition == "mc") %>% 
  mutate(age = as.numeric(Age.1),
         gender = substr(Gender.1, 1,1) ) %>% 
  count(id, age, gender)

```


Swedish participants (*N* = `r length(subs$id)`)  were recruited through advertising online and on the university campus (*M*~age~= `r mean(subs$age, na.rm = TRUE)`,  *SD*~age~ = `r sd(subs$age, na.rm = TRUE)`, Range = `r min(subs$age, na.rm = TRUE)` - `r max(subs$age, na.rm = TRUE)`). Self-identified gender was measured using an open-ended text box as recommended by @lindqvist_what_2020; participants were 35 women, 32 men and 1 who did not indicate gender). All participants were informed that participation was voluntary, that they could withdraw from the study and that results do no include any identifying features. The study was approved by the Stockholm University Ethical Review board. All participants provided written informed consent.

## Design

The experiment used a between-participants design with three response options conditions. These were the
*multiple categories*, *free text* and *binary categories*  conditions. The administering researcher was blind to participant condition and participants were randomly allocated into one of the three experimental conditions. 

## Stimuli 

For the gender categorization task, faces were produced using the London Face Database [@debruine_face_2017] and the  Chicago Face Database [@ma_chicago_2015] morphed with on Webmorph [@debruine_webmorph_2018]. For Black, Asian and White faces, the six most feminine faces of women and the six most masculine faces of men were selected, using the codebook provided by the researchers. The faces were matched, so that the most feminine faces in the database were morphed with the most masculine faces. The morphs were made in 7 steps, from completely feminine to completely masculine. For legibility, we refer to these faces in terms of facial femininity, acknowledging that this is a potential simplification for all the reasons outlined above. In other words, a face halfway on the morphing dimension contains 50% femininity. Because there were 18 pairs morphed in 7 steps, the total number of faces was 126.

## Measures

The primary outcome was responses to the categorization task. For analysis purposes, these were aggregated in the following ways:

*Beyond-binary categorizations* represented the categories where participants did not categorize the face as woman or man. This was a dichotomous variable that was calculated from the categorization data by combining the responses of “I don’t know” and “other” in the multiple categories condition. In the free text condition, this included various variations of "other" and "non-binary". These beyond-binary responses were coded as 1 and binary responses as 0. 

*Binary categorization* represented only the responses that were either woman (coded as 1) or man (coded as 0). All other responses were removed from this dataset.

## Procedure

Participants completed the experiment on a computer in a quiet room. Each trial consisted of a face accompanied by the question "How would you gender categorize this person?". Each person completed a total of 126 trials (i.e. they categorized every face in the stimuli set). Participants were randomly allocated into one of the three response options conditions: binary categories, multiple categories, and free text. In the binary categories condition, participants were only given the options to respond "woman" or "man". The multiple categories condition included the options “other” and “I don’t know” as well as woman or man. The free text condition consisted of an open text box.


## Data analysis

We used `r cite_r("r-references.bib", pkgs = c("brms", "tidyverse", "papaja"), withhold = FALSE)`. Additionally, much of the R code was adapted from @kurz_doing_2023 . Descriptive statistics were used to summarize the data, and Bayesian mixed-effects models were used to test the research questions. In all models, facial femininity was included as a factor. For all models, we included varying intercepts for both participants and trials. To answer each research question, we used a two-step approach which began with a model comparison approach followed by Bayes factor tests of specific contrasts.

### Research question 1: The use of categories beyond the binary

#### alternatively

Alternatively, we just looked at the individual level data and showed how likely each participant was to categorize a face as beyond the binary.

In Research Question one, we investigated whether participants categorized faces beyond the binary when given the option to do so. This could manifest as either a main effect of condition or an interaction between condition and facial femininity if categorizations beyond the binary were limited to only the most androgynous faces. For this analyses, the Binary categories condition was excluded, as that condition precluded the possibility of categorizing beyond the binary. The specific questions then, were "do people categorize faces beyond the binary?", "does this effect depend on condition?" and "are ambiguous faces more likely to be categorized beyond the binary?". These questions correspond to main effects of response option condition, facial femininity and an interaction between the two. 

Accordingly, the models were fit to the outcome *Beyond-binary categorizations* and comprised a Null model with no additional predictors, a Main effects model and an Interaction model  For full model specification (including priors) and model diagnostics, see the supplementary material. These model were then compared in terms of predictive power on out-of-sample data points, estimated using Leave-one-out cross validation (LOO-CV). This represents an indirect test of the research questions, and can be viewed as an imperfect analogy to checking whether there is a "significant" overall interaction in a classical F-test.

As a more direct test, we also calculated the Bayes Factor for the specific contrasts suggested by these questions. In other words, we compared the overall probability of making categorizations beyond the binary in the Free text condition and the Multiple categories conditions. Additionally,
we compared the prevalence of categorization beyond the binary specifically of the most androgynous faces. The Bayes factors were compared the null hypothesis that the contrast was equal to 0 and calculated using the Savage-Dickey Density Ratio. 

### Research question 2: The distribution of binary responses 

In Research Question 2, we investigated whether the distribution of *Binary responses* was different depending on response option condition. In other words, did the inclusion drastically change categorizations of women and men? This could manifest as a main effect of condition if there was an overall skew in the results or as an interaction between condition and morph level, in case that the skew was isolated to just one level of facial femininity (for example at the middle).

Similar to RQ1, this data was tested by fitting  Bayesian mixed models to the data. This included an initial model comparison approach, with Null model, and Main Effects model and an Interaction Model. If the model comparison did not preclude the Interaction model, we tested the contrast of the overall distribution as well as the difference between conditions at whichever level of facial femininity a visual inspection of the data suggested was the most strongly skewed.

# Results

The raw distribution of gender categorizations made by participants is presented in Figure\ \@ref(fig:descriptives).

```{r descriptives, fig.cap= "Gender Categorizations by Participants"}

# make figure 1
d %>%
  mutate(fem = fem ) %>% 
  filter(condition == "ft" | condition == "xb" | condition == "mc") %>% #select correct conditions
  group_by(fem, race, condition) %>% 
  mutate(categorization = recode(categorization,  #yes, this is pretty horrendous code, I haven't had a chance to sit down and clean it up yet.
                                 "1" = "Woman", "Woman" = "Woman", "wman" = "Woman", "woman" = "Woman", "female" = "Woman", "Female " = "Woman", "Female"= "Woman", "Fenale"= "Woman", "women" = "Woman", "woman " = "Woman", "femLE" = "Woman", "FEmale" = "Woman", "Femalw" = "Woman", "Fwmalw" = "Woman", "Female " = "Woman", "woman" = "Woman", "Woman" = "Woman", "feMale" = "Woman", "fermale" = "Woman", "wman" = "Woman", "Femae" = "Woman", "f" = "Woman", "F"= "Woman", "female " = "Woman",
                                 "2" = "Man", "man" = "Man","Male" = "Man", "male" = "Man", " Male" = "Man", "M" = "Man", "nmale" = "Man", "male " = "Man", "nale" = "Man", "ale" = "Man", "M" = "Man",  "m" = "Man", "MALE" = "Man",
                                 "3" = "Other", "Nonbinary" = "Other", "Non Binary " = "Other", "Non binary " = "Other",  "nonbinary" = "Other", 
                                 "4" = "Don't know" ),
         condition = recode(condition, "ft" = "Free text", "xb" = "Binary Categories", "mc" = "Multiple Categories"))%>% 
  count(categorization) %>% 
  filter(!is.na(categorization))%>% 
  ggplot(aes(x=fem, y=n, fill=factor(categorization, levels = c("Man", "Other", "Don't know", "Woman")))) +
  geom_bar(stat="identity", position = "fill") + 
  ggtitle("Gender Categorizations by Participants")+ 
  facet_wrap(~condition) + 
  scale_x_continuous(breaks =c(0, 17, 33, 50, 66, 83, 100)) +
  ylab("Proportion of responses" ) +
  xlab("Facial Femininity") +
  #scale_fill_discrete(name = "Response") +
  #scale_fill_viridis_d(name = "Response")
  scale_fill_grey( name = "Response")+
  theme_minimal()

 
```

```{r, modelfit}
#create dataframe with only free text and multiple categories conditions 
#Well, fist, first I wrangle data
tmp <- d %>% 
  filter(condition == "mc" | condition == "ft") %>% 
  mutate(categorization = recode(categorization, 
                                 "F" = "f", "kvinna" = "f", "female" = "f", "female " = "f", "Female"= "f", "Fenale"= "f", "women" = "f", "woman " = "f", "femLE" = "f", "FEmale" = "f", "Femalw" = "f", "Fwmalw" = "f", "Female " = "f", "woman" = "f", "Woman" = "f", "feMale" = "f", "fermale" = "f", "wman" = "f", "Femae" = "f",
                                 "man" = "m","Male " = "m", "make" = "m", "Male"= "m", "male" = "m", "man " = "m",  "male " = "m", "guy" = "m", "boy" = "m", "Make" = "m", "M"  = "m", "Man" = "m", "Bottom half male; above nose female., Would have to say Male" = "m", " male" = "m", "male  " = "m", "ale" = "m", "nmale" = "m", "MALE"= "m", "nale"= "m", " Male" = "m",
                                 "Nonbinary" = "o", "Non Binary " = "o", "Unsure" = "o", "Non binary " = "o", "good" = "o", "Neutral" = "o", "neutral" = "o", "nonbinary" = "o", "bigender" = "o", "hen" = "o", "don't know"  = "o", "Bottom half male, nose upwards female" = "o" )) %>% 
  mutate(bbcat = ifelse(categorization == "o"|categorization == "4", 1, 0),
         fem = as.factor(fem))

#Fit models using brms.
#Can be run with premade file to save time. To reproduce in full, comment out the "file" argument
Null <- brm(bbcat ~ 1  + (1 |id) + (1|face:fem), family = bernoulli(link = 'logit'), 
          prior = c(prior(normal(0,3), class = "Intercept"), # weakly regularizing priors
                    prior(cauchy(0,3), class = "sd")
                    ),
          data = tmp,
          iter = 6000, warmup = 2000,
          chains = 4,
          cores = 4,
          sample_prior = TRUE,
          file = "models/binary_null"
          )

#Fitting the main effects model
Main_Effect <- brm(bbcat ~ 0 + condition + fem  + (1 |id) + (1|face:fem), family = bernoulli(link = 'logit'), 
          prior = c(prior(normal(0,3), class = "b", coef = "conditionmc"), #again, weakly regularizing priors
                    prior(normal(0,3), class = "b", coef = "conditionft"),
                    prior(cauchy(0,3), class = "sd")
                    ),
          data = tmp,
          iter = 4000, warmup = 1000,
          chains = 4,
          cores = 4,
          sample_prior = TRUE,
          file = "models/binary_mfx"
          )

#fitting the interaction model
Interaction <- brm(bbcat ~ 0 + condition:fem  + (1 |id) + (1|face:fem), family = bernoulli(link = 'logit'), 
         prior = c(prior(normal(-3,3), class = "b"),
                   prior(cauchy(0,3), class = "sd")),
          data = tmp,
          iter = 6000, warmup = 2000,
          chains = 4,
          cores = 4,
          sample_prior = TRUE,
          file = "models/binary_int.5"
          )

```

```{r, loo}
library(loo)
# running to reproduce the analyses, uncomment the next three lines
#loo1 <- loo(null) %>% saveRDS("loo1.rds")
#loo2 <- loo(main_effect, mc_cores =4) %>% saveRDS("loo2.rds")
#loo3 <- loo(interaction, mc_cores =4) %>% saveRDS("loo3.rds")

#otherwise lood loo from file
loo1 <- readRDS("models/loo1.rds")
loo2 <- readRDS("models/loo2.rds")
loo3 <- readRDS("models/Loo3.rds")

#prepare to turn into apa tables
loo_table <- loo_compare(loo1, loo2, loo3)  
row.names(loo_table) = c("Interaction", "Main Effect", "Null")

library(knitr)
library(kableExtra)

#make nice apa tables
kable(
  loo_table[,1:4] %>% round(2),
  booktabs = "TRUE",
  format = "latex",
  col.names = c("LOO diff", "St. Error diff", "LOO", "St. Error LOO"),
  align = c("c", "c", "c", "c"),
  caption = "Relative predictive power of models describing the outcome on the categorization task"
  ) %>% 
  kable_classic(full_width = F) %>% 
  footnote(
    general_title = "Note.",
    general = "LOO diff refers to the difference in loo between the model and the most predictive model. The first row describes the most predictive model, which is why the difference is 0",
    threeparttable = TRUE,
    footnote_as_chunk = TRUE
    ) 
```

To investigate whether response options affected gender categorization  we fit a Null Model, a Main Effects Model and an Interaction model to the data. As stated, for these analyses, the Binary Categories condition was excluded, as participant did not have the option to categorize beyond the binary. The results of model comparison are presented in Table\ \@ref(tab:loo). 
Table\ \@ref(tab:loo) suggests that the Interaction model is the most predictive. However the absolute difference between the Interaction model and the Main effects model is small and importantly, the difference is small in relation to the standard error of the difference. This suggests that the data is inconclusive about which model is most suitable, although both are superior to the Null model. As model comparison did not conclusively preclude the Interaction model, we continued by testing specific, relevant contrasts using the Interaction model (see the Supplementary material for specific contrast weights).
 

```{r exp-one-inf, fig.cap= "Proportion of beyond-binary responses in the Multiple Categories and Free Text conditions"}
# Use brms to sample from the posterior
c_eff <- conditional_effects(Interaction) 

#turn into useful dataframe
df <-   as.data.frame(c_eff[["condition:fem"]])

#Visualise model-based estimates
ggplot(df,aes(x = fem, y=estimate__, group=condition))+
  geom_point(aes(color=condition), position = position_dodge(0.4))+
  geom_errorbar(aes(ymin=lower__, ymax=upper__, color = condition), position = position_dodge(0.4), width = 0.3) + 
  scale_color_brewer(name = "Condition",
                   labels = c("Free text", "Multiple Conditions"))+
  ylab("Proportion of responses" ) +
  xlab("Facial femininity")+
  theme_apa()
  
```

```{r, calculating for tests, message =FALSE, error=FALSE}

#Testing the hypothesis using BRMS built in hypothesis function, which uses the savage-dickey density ratio. h0 compares the avearage in the multiple comoparisions condition to the average in the free text condition.
h0 <- hypothesis(Interaction,
                 "(conditionmc:fem16.67 + conditionmc:fem33.33 + conditionmc:fem0 + conditionmc:fem50 + conditionmc:fem66.67 + conditionmc:fem83.33 + conditionmc:fem100)/7 = (conditionft:fem16.67 + conditionft:fem33.33 + conditionft:fem0 + conditionft:fem50 + conditionft:fem66.67 + conditionft:fem83.33 +  conditionft:fem100)/7
                 ") 
#Testing the hypothesis using BRMS built in hypothesis function, which uses the savage-dickey density ratio. h1 compares the average in the multiple comparisons condition at facial femininity = 50 to free text at facial femininity = 50
h1 <- hypothesis(Interaction, "conditionmc:fem50=conditionft:fem50") 

#h2 assigns quadratic weights to both conditions. 
h2 <- hypothesis(Interaction, "(conditionmc:fem16.67*0 + conditionmc:fem33.33 *3 + conditionmc:fem0*(-5) + conditionmc:fem50*4 + conditionmc:fem66.67 *3 + conditionmc:fem83.33*0 + conditionmc:fem100*(-5))/84 = (conditionft:fem0*(-5) +conditionft:fem16.67 *0 + conditionft:fem33.33 *3  + conditionft:fem50 * 4 + conditionft:fem66.67 *3 + conditionft:fem83.33 *0+  conditionft:fem100 * (-5))/84 
                  ")


```

Model parameters are visualized in Figure\ \@ref(fig:exp-one-inf). First, whether participants overall made more beyond-binary categorizations in the multiple categories condition than in the free text condition. Although the incidence was rare in both conditions (as is clear from Figure\ \@ref(fig:descriptives)) the evidence suggests fairly convincingly that participants made more beyond-binary categorizations in the Multiple Categories than in the Free Text is the case (OR = `r exp(h0$hypothesis$Estimate %>% round(2))`, CI =[`r exp(h0$hypothesis$CI.Lower%>% round(2))`, `r exp(h0$hypothesis$CI.Upper %>% round(2))`], BF~10~= `r round(1/h0$hypothesis$Evid.Ratio , 2) `). Additionally, based on visual inspection of Figure\ \@ref(fig:exp-one-inf), which suggested that the difference between the condition was concentrated at morphs containing equal levels of femininity and masculinity (i.e. facial femininity = 50%), we explored whether the evidence supported this difference at facial femininity = 50%. There was moderate evidence that participants made more beyond-binary categorizations in the Multiple Categories condition than the Free text condition at facial femininity = 50% (OR = `r exp(h1$hypothesis$Estimate %>% round(2))`, CI =[`r exp(h1$hypothesis$CI.Lower %>% round(2))`, `r exp(h1$hypothesis$CI.Upper %>% round(2))`], BF~10~=  `r round(1/h1$hypothesis$Evid.Ratio,2)`). Lastly, we tested the difference using quadratic weights, though here the difference was inconclusive  (OR = `r exp(h2$hypothesis$Estimate %>% round(2))`, CI = [`r exp(h2$hypothesis$CI.Lower %>% round(2))`,`r exp(h2$hypothesis$CI.Upper %>% round(2))`], BF~10~=  `r round(1/h2$hypothesis$Evid.Ratio,2 )`). 

Overall the evidence suggests at least somewhat strongly that when participants have the option of using beyond-binary response options, they use them. 

Subsequently, we tested whether the inclusion of non-binary response options skewed the distribution of categorization of faces as women and men. For this analysis, therefore, we tested the outcome variable *binary categorization*, excluding "other" "I don't know" and any other responses in the free text condition.

```{r, rq2-modelling 3, message=FALSE}
#remove the beyond binary responses
tmp <- d %>% 
  filter(condition == "mc"| condition == "xb"|condition == "ft" )%>% 
  mutate(categorization = recode(categorization, 
                                 "F" = "f", "kvinna" = "f", "female" = "f", "female " = "f", "Female"= "f", "Fenale"= "f", "women" = "f", "woman " = "f", "femLE" = "f", "FEmale" = "f", "Femalw" = "f", "Fwmalw" = "f", "Female " = "f", "woman" = "f", "Woman" = "f", "feMale" = "f", "fermale" = "f", "wman" = "f", "Femae" = "f",
                                 "man" = "m","Male " = "m", "make" = "m", "Male"= "m", "male" = "m", "man " = "m",  "male " = "m", "guy" = "m", "boy" = "m", "Make" = "m", "M"  = "m", "Man" = "m", "Bottom half male; above nose female., Would have to say Male" = "m", " male" = "m", "male  " = "m", "ale" = "m", "nmale" = "m", "MALE"= "m", "nale"= "m", " Male" = "m",
                                 "Nonbinary" = "o", "Non Binary " = "o", "Unsure" = "o", "Non binary " = "o", "good" = "o", "Neutral" = "o", "neutral" = "o", "nonbinary" = "o", "bigender" = "o", "hen" = "o", "don't know"  = "o", "Bottom half male, nose upwards female" = "o",
                                 "1" = "f", "2" = "m")) %>% 
  mutate(f_cat = ifelse(categorization == "f"|categorization == "m", categorization, NA),
         fem = as.factor(fem)) %>% 
  mutate(f_cat =as.numeric( f_cat == "f"))

#Start fitting the null model
Null <- brm(f_cat ~ 1  + (1 |id) + (1|face:fem), family = bernoulli(link = 'logit'), 
          prior = c(prior(normal(0,3), class = "Intercept"),
                    prior(exponential(2), class = "sd")
                    ),
          data = tmp,
          iter = 6000, warmup = 2000,
          chains = 4,
          cores = 4,
          sample_prior = TRUE,
          file = "models/fit_mf_null"
          )


#Main effects model
main_effects <- brm(f_cat ~ 0 + condition + fem  + (1 |id) + (1|face:fem), family = bernoulli(link = 'logit'), 
          prior = c(prior(normal(0,3), class = "b"),
                    prior(cauchy(0,3), class = "sd")),
          data = tmp,
          iter = 4000, warmup = 1000,
          chains = 4,
          cores = 4,
          sample_prior = TRUE,
          file = "models/mainfx.2"
          )

#Lastly the interaction model
interaction <- brm(f_cat ~ 0 + condition:fem  + (1 |id) + (1|face:fem), family = bernoulli(link = 'logit'), 
         prior = c(prior(normal(0,3), class = "b"),
                   prior(cauchy(0,3), class = "sd")),
          data = tmp,
          iter = 6000, warmup = 2000,
          chains = 4,
          cores = 4,
          sample_prior = TRUE,
          file = "models/fit_mf_int.2"
          )

```

```{r, rq2-table, fig.cap= "Proportion of beyond-binary responses in the Multiple Categories and Free Text conditions"}

#Same as before
#loo_b1 <- loo(Null, mc_cores = 4) %>% saveRDS("loo_b1.rds")
#loo_b2 <- loo(main_effects, mc_cores = 4) %>% saveRDS("loo_b2.rds")
#loo_b3 <- loo(interaction, mc_cores = 4) %>% saveRDS("loo_b3rds")

#again, loading loo from file
loo_b1 <- readRDS("models/loo_b1.rds")
loo_b2 <- readRDS("models/loo_b2.rds")
loo_b3 <- readRDS("models/loo_b3.rds")

#this is prepare to make into Apa style table
loo_table2 <- loo_compare(loo_b1, loo_b2, loo_b3)

row.names(loo_table2) = c( "Main Effect", "Null", "Interaction")


library(knitr)
library(kableExtra)

#Make apa style table
kable(
  loo_table2[,1:4] %>% round(2),
  booktabs = "TRUE",
  col.names = c("LOO difference", "St. Error diff", "LOO", "St. Error LOO"),
  #row.names = c("Free text", "Multiple categories", "Binary categories"),
  align = c("l", "c", "c", "c"),
  caption = "Relative predictive power of models describing the outcome on the categorization task"
  ) %>% 
  kable_classic(full_width = F) %>% 
  footnote(
    general_title = "Note.",
    general = "LOO diff refers to the difference in loo between the model and the most predictive model. The first row describes the most predictive model, which is why the difference is 0",
    threeparttable = TRUE,
    footnote_as_chunk = TRUE
  )

```

```{r hypos 2}

#Test contrasts
h0 <- hypothesis(interaction, "conditionft:fem50 = conditionmc:fem50")
h1 <- hypothesis(interaction, "conditionxb:fem50 = conditionmc:fem50")




```



To test this research question, we first carried out model comparison. The results of this are presented in Table\ \@ref(tab:rq2-table). Again, we compared a Null model, a Main Effects model and an Interaction model. Although the Interaction model was the worst in terms of LOO-CV, the standard errors were quite large relative to the difference, again suggesting that the model comparison was inconclusive and the existence of an interaction could not be excluded. For completeness we therefore carried out the contrast analyses using the Interaction model. 

Based on the pattern in Figure\ \@ref(fig:descriptives), which seems to show that in the Multiple Categories condition, participants made fewer "man" responses compared to the other condition, we compared the distribution of woman/man responses at facial femininity = 50%. The evidence were slightly in favor of there being no difference between the multiple categories and the free text conditions (OR = `r exp(h0$hypothesis$Estimate %>% round(2))`, CI =[`r exp(h0$hypothesis$CI.Lower%>% round(2))`, `r exp(h0$hypothesis$CI.Upper %>% round(2))`], BF~01~= `r round(h0$hypothesis$Evid.Ratio , 2) `) and moderately in favor of no difference between multiple categories and binary categories conditions (OR = `r exp(h1$hypothesis$Estimate %>% round(2))`, CI =[`r exp(h1$hypothesis$CI.Lower%>% round(2))`, `r exp(h1$hypothesis$CI.Upper %>% round(2))`], BF~01~= `r round(h1$hypothesis$Evid.Ratio , 2) `). In other words, the evidence suggests that when participants categories faces beyond the binary, this does not skew the categorizations of women and men in any direction.

# Discussion

Eexperiment 1 indicated that participants categorize beyond the binary when response options include more options than women and men only.  However, the free text option did not differ from the binary option. Thus, the written out choices seem to act as reminders to participants.  Furthermore,  categorization beyond the binary affected former man and women responses to similar degrees, meaning that the ratio of women and men categorizations was still about 50/50. This did not systematically affect their overall pattern of responses in terms of woman and man categorizations.


# Study 2

Study  2 tested whether continuous scales that measure woman and men separately reduce categorical perception. To that end, we once again borrowed from the literature on self-categorization, this time using [@bem_measurement_1974] method of measuring gender on two separate scales. First, we investigated whether there was a categorical perception effect. We investigated this by examining the individual level data. 
If categorical perception occurs, ratings of woman and man should be skewed near facial femininity = 50. In other words, a face with 33.33% facial femininity would be rated as less woman than that. Therefore, we examined the differences between the two conditions at facial femininity = 33.33% and 66.67%,

# Method

### Participants

Participants (*N* = 49)  were recruited through advertising online and on the university campus (*M*~age~= 36.67,  *SD*~age~ = 12.54).Self-identified gender was measured using an open-ended text box; 25 women and 24 men participated. Participants were monetarily compensated for their time. All participants were informed that participation was voluntary and gave written consent to participate in the study in accordance with ethical recommendations. The participants were randomly allocated to conditions. 

## Stimuli & Procedure

The stimuli and procedure for study 2 were identical to experiment 1 but included only two conditions. Study 2 differed only the response options conditions, such that response option conditions consisted of a single dimension, which ranged from “woman” to “man” and “multiple dimension” which ranged from “not woman” to “woman” and “not man” to “man”. For the multiple dimensions condition, participants rated the same faces according to both scales, but on separate trials. This differed from @bem_measurement_1974, who used scales of "femininity" and "masculinity". The present anchors were chosen because gender categorization was the focus of the present study.

## Data analysis

Research question 3 asked whether whether participants would view faces less categorically in when they categorized them using multiple dimensions (i.e. Not woman - Woman/Not man -Man) than when they used the single dimension (Woman-Man). We expected to see a difference between the two conditions at fecial feminiity = 33.33 and 66.67 as these were the closes to the midway point. In other words, if categorical perception is reduced, we would expect to see an interaction between  condition and facial femininity level, but not a main effect. To test this, we fit a single Bayesian mixed-effects model which calculated unique fixed intercepts at each intersection of facial femininity and condition as well as varying intercepts for participants and faces (See supplemental material for full model specification). Using Savage-Dickey density ratios, we calculated the Bayes Factors for the contrasts between single dimension condition and multiple dimension at Facial Femininity = 33.37 and 66.66. 

# Results

## Research Question 3: 
Most participants accentuated their ratings toward the poles ()

The mean ratings in both conditions are presented in Figure\ \@ref(fig:descriptives-two). 

```{r descriptives-two, fig.cap= "Mean ratings of faces in Single dimension and multiple dimensions"}
#Visualise means using ggplot
d %>% 
  filter(condition == "md" | condition == "sd") %>% 
  mutate(fem = fem+50,
         categorization = as.numeric(categorization) %>% ifelse(scale == "m" | condition == "sd", 100-., .),
         scale = recode(scale, "1" = "Woman - Man", "f" = "Not Woman - Woman", "m" = "Not Man - Man"),
         condition = recode(condition, "sd" = "Single Dimension", "md" = "Multiple Dimensions")) %>% 
  mutate (categorization = categorization  +50)%>% 
  group_by(fem, scale, condition) %>% 
  summarise(mean_rating = mean(categorization)) %>% 
  ggplot(aes(x=fem, y=mean_rating, group = scale)) +
  geom_line(aes(color = scale))+
  geom_point(aes(color = scale))+
  theme_minimal()+
  facet_wrap(~condition) +
  scale_x_continuous(breaks =c(0, 17, 33, 50, 67, 83, 100)) +
  ylab("Mean \"woman\" rating" ) +
  xlab("Proportion female face in the morph") +
  scale_color_brewer(name = "Condition")+
  theme_apa() 



  
```

```{r}

#Visualise means using ggplot
sd <- d %>% 
  filter(condition == "md" | condition == "sd") %>% 
  mutate(fem = fem,
         categorization = as.numeric(categorization) %>% ifelse(scale == "m" | condition == "sd", 100-., .),
         scale = recode(scale, "1" = "Woman - Man", "f" = "Not Woman - Woman", "m" = "Not Man - Man"),
         condition = recode(condition, "sd" = "Single Dimension", "md" = "Multiple Dimensions")) %>% 
  mutate (categorization = categorization  )%>% 
  group_by(fem, scale, condition) %>% 
  summarise(mean_rating = mean(categorization))

f <- d %>% 
  filter(condition == "md" & scale == "f") %>% 
  mutate(fem = fem,
         categorization = as.numeric(categorization) %>% ifelse(scale == "m" | condition == "sd", 100-., .),
         scale = recode(scale, "1" = "Woman - Man", "f" = "Not Woman - Woman", "m" = "Not Man - Man"),
         condition = recode(condition, "sd" = "Single Dimension", "md" = "Multiple Dimensions")) %>% 
  mutate (categorization = categorization  )%>% 
  group_by(fem, scale, condition, id) %>% 
  summarise(mean_rating = mean(categorization)) 

m <- d %>% 
  filter(condition == "md"& scale == "m" | condition == "sd") %>% 
  mutate(fem = fem,
         categorization = as.numeric(categorization) %>% ifelse(scale == "m" | condition == "sd", 100-., .),
         scale = recode(scale, "1" = "Woman - Man", "f" = "Not Woman - Woman", "m" = "Not Man - Man"),
         condition = recode(condition, "sd" = "Single Dimension", "md" = "Multiple Dimensions")) %>% 
  mutate (categorization = categorization  )%>% 
  group_by(fem, scale, condition, id) %>% 
  summarise(mean_rating = mean(categorization)) 

ggplot(data = sd, aes(x=fem, y=mean_rating, color = scale)) +
  geom_line(aes(group = scale))+
  geom_point(aes(group = scale))+
  geom_point(data = f, 
            aes(x=fem, y=mean_rating, group = id ), alpha = 0.3)+
  geom_line(data = f, 
            aes(x=fem, y=mean_rating, group = id ), alpha = 0.3)+
  geom_point(data = m, 
            aes(x=fem, y=mean_rating,  group = id),  alpha = 0.3 )+
  geom_line(data = m, 
            aes(x=fem, y=mean_rating,  group = id),  alpha = 0.3 )+
  theme_minimal()+
  facet_wrap(~condition) +
  scale_x_continuous(breaks =c(0, 17, 33, 50, 67, 83, 100)) +
  ylab("Mean \"woman\" rating" ) +
  xlab("Proportion female face in the morph") +
 # scale_color_brewer(name = "Condition")+
  theme_apa() 




```



```{r, fig.cap= "Mean rating of woman across the md and sd condition"}
#Wrangle data again
tmp <- d %>% 
  filter(condition == "sd" | condition == "md") %>% 
  mutate(f_rating = as.numeric(categorization) %>%  ifelse(scale == "f", ., 100- .),
         scale_new = ifelse(scale == "f" | scale =="m", scale, "sd"),
         fem = as.factor(fem)) 


fit_dimensional_interaction <- 
  brm(f_rating ~ 0 + fem:condition + (1 + masc|id) + (1|face), family = gaussian(link = 'identity'), 
          prior = c(prior(normal(50,50), class = "b"),
                    #prior(normal(50,50), class = "Intercept"),
                    prior(exponential(1), class = "sd"),
                    prior(lkj(1), class = "cor"),
                    prior(exponential(1), class = sigma)),
          data = tmp,
          iter = 4000, warmup = 1000,
          cores = 4,
          sample_prior = TRUE,
          file = "models/fit_dimensional_stair_factor.3")





# carrying out the hypothesis test
h_dim_33 <- hypothesis(fit_dimensional_interaction, "fem33.33:conditionmd= fem33.33:conditionsd" )
h_dim_67 <- hypothesis(fit_dimensional_interaction, "fem66.67:conditionmd= fem66.67:conditionsd" )
```

```{r exp-two-inf, fig.cap= "Mean gender ratings in Single Dimension and Multiple Dimensions conditions"}
# Use brms to sample from posterior
c_eff <- conditional_effects(fit_dimensional_interaction) 

df <- as.data.frame(c_eff[["fem:condition"]])

ggplot(df,aes(x = fem, y=estimate__, group=condition))+
  geom_line(aes(color=condition), position = position_dodge(0.4)) +
  geom_point(aes(color=condition), position = position_dodge(0.4))+
  geom_errorbar(aes(ymin=lower__, ymax=upper__, color = condition), position = position_dodge(0.4), width = 0.3) + 
  scale_color_grey(name = "Condition",
                   labels = c("Single Dimension", "Multiple Dimensions"))+
  ylab("Mean rating" ) +
  xlab("Proportion female face in the morph")+
  theme_apa()
  
```

We compared the mean rating at facial femininity =  33.33 and 66.67 morph for both conditions. At facial femininity = 33.33 the evidence strongly suggested that the two conditions were the same
(Estimate = `r h_dim_33 $hypothesis$Estimate %>% round(2)`, CI =[`r h_dim_33 $hypothesis$CI.Lower%>% round(2)`, `r h_dim_33 $hypothesis$CI.Upper %>% round(2)`], BF~01~= `r round(h_dim_33 $hypothesis$Evid.Ratio , 2) `). This was also the case at facial femininity = 66.67 
(Estimate = `r h_dim_67$hypothesis$Estimate %>% round(2)`, CI =[`r h_dim_67$hypothesis$CI.Lower%>% round(2)`, `r h_dim_67$hypothesis$CI.Upper %>% round(2)`], BF~01~= `r round(h_dim_67$hypothesis$Evid.Ratio , 2) `). Overall, both conditions showed fairly strong tendencies toward categorical perception and they did not differ in this regard. 

# Discussion

Study 2 showed that participants exhibited signs of categorical perception when rating faces in terms of gender. Additionally, this did not depend on response option condition; response options which did not present women and men as opposing categories led to an equal amount of categorical perception as response options that did. Indeed a highly binary view of gender was present and participants treated womanhood and manhood as opposites even the scale would allow them to be more flexible. 

# General discussion

In two experiments, we tested how response options in gender categorization of others influence binary gender categorization.  Specifically, the results provided strong evidence that participants only use beyond-binary options to categorize faces when such options are provided explicitly. Free text answers or continuous scales did not affect participants binary gender categorization. Additionally, response options which did not present women and men as opposing categories did not induce participant's perception of gender in faces to be less binary. 

These findings are somewhat consistent with previous research, such as the work of @saperstein_categorical_2021 and @lindqvist_what_2020, which has shown that including flexible response options allow participants to better express themselves. Unlike the literature on self-categorization, increased freedom did not increase the gender diversity of participants' categorizations, rather explicit reminders seem to have the largest effect. When participants categorized women or men on continuous scales, the results differ from @bem_measurement_1974 who found that participants categorize their own femininity and masculinity independently of each other. Rather, when categorizing others, the participants in the present study seemed to treat women and men as opposites, even when the response options did not pose them as such. Both of these deviations from the previous literature likely stem from the substantial difference between indicating one's own gender and categorizing that of others.

It is worth noting that this study only examined participants' stated categorizations, and it is possible that they may have made other categorizations internally that were not reflected in their responses. However, it is important to recognize that a purely behavioral study such as this cannot fully capture the neurological processes underlying gender perception, which may require more sophisticated techniques such as fMRI and EEG [@kloth_neural_2010; @stolier_neural_2017].

In this study we aggregated responses that did not indicate woman or man. In the multiple response option condition, both “I don’t know” and “Non-binary” were included as a beyond binary categorization. We justified this on the basis that what we were interested in is any categorization beyond the binary. However, these two options are not the same. Furthermore, it is important to note that no matter how a person looks, it is impossible to know their binary or non-binary gender identity [@richards_non-binary_2016]. Therefore, if a person aims to be inclusive and not categorize in a binary way, then abstaining from categorizing, for examle by selecting "I don't know" is always the best option.

In the introduction we raised the possibility that findings within gender categorization research may be biased from a sole reliance on binary response options. Based on the present results, this seems unlikely. Instead, it seems that the societal norm to treat gender as binary is the strongest determinant participants gender categorizations. Even so, we recommend researchers to carefully consider their measurements of gender categorization. Open text-boxes, forced choice-alternatives and dimensional scales are all viable alternatives. Even researchers who are primarily interested in binary categorizations should consider including beyond-binary alternatives, to avoid perpetuating the binary gender norm and to accurately represent the diversity of gender.

#### Conclusion

In two experiments we tested how different response alternatives affected gender categorizations. Participants were more likely to categorize faces beyond the binary when using a forced-choice paradigm including “non-binary” and “I don’t know” than when using a free text option, or slider scales. In comparison to self-identification questions where open ended responses are seen as the most inclusive alternative [@lindqvist_what_2020], categorization of others benefit from response options that explicitly reminds participants that not all people identify as women or men.


\newpage

# References

::: {#refs custom-style="Bibliography"}
:::

## Looking at the outcome beyond-binary

```{r}
#create dataframe with only free text and multiple categories conditions 
#Well, fist, first I wrangle data

d <- d %>% 
  mutate(gbb_m = rowMeans(d %>% select(starts_with("gender_")))) %>% 
  mutate(gbb_s = gbb_m - mean(gbb_m, na.rm = TRUE))

tmp <- d %>% 
  filter(condition == "mc" | condition == "ft") %>% 
  mutate(categorization = recode(categorization, 
                                 "F" = "f", "kvinna" = "f", "female" = "f", "female " = "f", "Female"= "f", "Fenale"= "f", "women" = "f", "woman " = "f", "femLE" = "f", "FEmale" = "f", "Femalw" = "f", "Fwmalw" = "f", "Female " = "f", "woman" = "f", "Woman" = "f", "feMale" = "f", "fermale" = "f", "wman" = "f", "Femae" = "f",
                                 "man" = "m","Male " = "m", "make" = "m", "Male"= "m", "male" = "m", "man " = "m",  "male " = "m", "guy" = "m", "boy" = "m", "Make" = "m", "M"  = "m", "Man" = "m", "Bottom half male; above nose female., Would have to say Male" = "m", " male" = "m", "male  " = "m", "ale" = "m", "nmale" = "m", "MALE"= "m", "nale"= "m", " Male" = "m",
                                 "Nonbinary" = "o", "Non Binary " = "o", "Unsure" = "o", "Non binary " = "o", "good" = "o", "Neutral" = "o", "neutral" = "o", "nonbinary" = "o", "bigender" = "o", "hen" = "o", "don't know"  = "o", "Bottom half male, nose upwards female" = "o" )) %>% 
  mutate(bbcat = ifelse(categorization == "o"|categorization == "4", 1, 0),
         fem = as.factor(fem))
```


First question: does GBB predict bbcategories? Maybe, but there's so few, it's hard to tell.
```{r}
#fitting the mfx model
fit_bbcat_gbb <- brm(bbcat ~ 0 +  gbb_s +condition + (1 |id) + (1|face:fem), family = bernoulli(link = 'logit'), 
         prior = c(prior(normal(-3,3), class = "b"),
                   prior(cauchy(0,3), class = "sd")),
          data = tmp,
          iter = 6000, warmup = 2000,
          chains = 4,
          cores = 4,
          sample_prior = TRUE,
          file = "models/fit_bbcat_gbb"
          )
```

But what if we add an interaction??

```{r}
fit_bbcat_gbb_int <- brm(bbcat ~ 1 +  gbb_s *condition + (1 |id) + (1|face:fem), family = bernoulli(link = 'logit'), 
         prior = c(prior(normal(0,3), class = "b"),
                   prior(normal(-3,3), class = "Intercept"),
                   prior(cauchy(0,3), class = "sd")),
          data = tmp,
          iter = 6000, warmup = 2000,
          chains = 4,
          cores = 4,
          sample_prior = TRUE,
          file = "models/fit_bbcat_gbb_mfx"
          )
conditional_effects(fit_bbcat_gbb_int)


```
Might as well add here, what happens when we look at the outcome beyond-binary in the same way?

```{r}
bb_Null <- brm(bbcat ~ 1  + (1 |id) + (1|face:fem), family = bernoulli(link = 'logit'), 
          prior = c(prior(normal(0,3), class = "Intercept"), # weakly regularizing priors
                    prior(cauchy(0,3), class = "sd")
                    ),
          data = tmp,
          iter = 6000, warmup = 2000,
          chains = 4,
          cores = 4,
          sample_prior = TRUE,
          file = "models/binary_null"
          )
```

```{r}
library(gridExtra)
bb_pp <- ranef(bb_Null)$i %>% as_tibble()

a <- d %>%
  filter(d$condition == "ft"|d$condition == "mc" )%>% group_by(id, condition) %>% 
  summarise(gbb = mean(gbb_s))

ind_ft <- cbind(a, bb_pp) %>% filter(condition == "ft")
ind_mc <- cbind(a, bb_pp) %>% filter(condition == "mc")



figure_ft <- ind_ft %>%
  as_tibble() %>%
  rownames_to_column() %>%
  arrange(Estimate.Intercept) %>%
  mutate(id = seq_len(n())) %>%
  ggplot(aes(id, Estimate.Intercept, ymin = Q2.5.Intercept, ymax = Q97.5.Intercept)) + 
    geom_pointrange(alpha = 0.7) +
    coord_flip() + labs(x = "Person Number (Sorted)")+
  theme_classic()


figure_mc <- ind_mc %>%
  as_tibble() %>%
  rownames_to_column() %>%
  arrange(Estimate.Intercept) %>%
  mutate(id = seq_len(n())) %>%
  ggplot(aes(id, Estimate.Intercept, ymin = Q2.5.Intercept, ymax = Q97.5.Intercept)) + 
    geom_pointrange(alpha = 0.7) +
    coord_flip() + labs(x = "Person Number (Sorted)")+
  theme_classic()

grid.arrange(figure_ft, figure_mc, ncol = 2)
```



## looking at scale 

```{r}
d <- d %>% 
  mutate(gbb_m = rowMeans(d %>% select(starts_with("gender_")))) %>% 
  mutate(gbb_s = gbb_m - mean(gbb_m, na.rm = TRUE))

#Wrangle data again
tmp <- d %>% 
  filter(condition == "sd" | condition == "md") %>% 
  mutate(f_rating = as.numeric(categorization) %>%  ifelse(scale == "f", ., 100- .),
         scale_new = ifelse(scale == "f" | scale =="m", scale, "sd"),
         fem = as.factor(fem)) 


fit_dimensional_interaction_gbb <- 
  brm(f_rating ~ fem*condition*gbb_s + (1 + masc|id) + (1|face), family = gaussian(link = 'identity'), 
          prior = c(prior(normal(0,20), class = "b"),
                    prior(normal(50,50), class = "Intercept"),
                    prior(exponential(1), class = "sd"),
                    prior(lkj(1), class = "cor"),
                    prior(exponential(1), class = sigma)),
          data = tmp,
          iter = 4000, warmup = 1000,
          cores = 4,
          sample_prior = TRUE,
          file = "models/fit_dimensional_interaction_gbb_2")

conditional_effects(fit_dimensional_interaction_gbb)

```


# Looking at women/men 

I can actually start with my old null model, just to see if some people are more likely to have a female or male bias. Seems like we have a farily even spread.


```{r, rq2-modelling, message=FALSE}
#remove the beyond binary responses
tmp <- d %>% 
  filter(condition == "mc"| condition == "xb"|condition == "ft" )%>% 
  mutate(categorization = recode(categorization, 
                                 "F" = "f", "kvinna" = "f", "female" = "f", "female " = "f", "Female"= "f", "Fenale"= "f", "women" = "f", "woman " = "f", "femLE" = "f", "FEmale" = "f", "Femalw" = "f", "Fwmalw" = "f", "Female " = "f", "woman" = "f", "Woman" = "f", "feMale" = "f", "fermale" = "f", "wman" = "f", "Femae" = "f",
                                 "man" = "m","Male " = "m", "make" = "m", "Male"= "m", "male" = "m", "man " = "m",  "male " = "m", "guy" = "m", "boy" = "m", "Make" = "m", "M"  = "m", "Man" = "m", "Bottom half male; above nose female., Would have to say Male" = "m", " male" = "m", "male  " = "m", "ale" = "m", "nmale" = "m", "MALE"= "m", "nale"= "m", " Male" = "m",
                                 "Nonbinary" = "o", "Non Binary " = "o", "Unsure" = "o", "Non binary " = "o", "good" = "o", "Neutral" = "o", "neutral" = "o", "nonbinary" = "o", "bigender" = "o", "hen" = "o", "don't know"  = "o", "Bottom half male, nose upwards female" = "o",
                                 "1" = "f", "2" = "m")) %>% 
  mutate(f_cat = ifelse(categorization == "f"|categorization == "m", categorization, NA)) %>% 
  mutate(f_cat =as.numeric( f_cat == "f"))

#Start fitting the null model
Null <- brm(f_cat ~ 1  + (1 |id) + (1|face:fem), family = bernoulli(link = 'logit'), 
          prior = c(prior(normal(0,3), class = "Intercept"),
                    prior(exponential(2), class = "sd")
                    ),
          data = tmp,
          iter = 6000, warmup = 2000,
          chains = 4,
          cores = 4,
          sample_prior = TRUE,
          file = "models/fit_mf_null"
          )
```

## without coefs, what are the persona and item parameters?

```{r}
(person_pars <- ranef(Null)$id)

person_pars[, , "Intercept"] %>%
  as_tibble() %>%
  rownames_to_column() %>%
  arrange(Estimate) %>%
  mutate(id = seq_len(n())) %>%
  ggplot(aes(id, Estimate, ymin = Q2.5, ymax = Q97.5)) + 
    geom_pointrange(alpha = 0.7) +
    coord_flip() + labs(x = "Person Number (Sorted)")+
  theme_classic()
```

And then see if this is correlated with Gener binary belief. It isn't!

```{r, rq2-modelling 2, message=FALSE}
s <- d %>%
  filter(d$condition == "ft"|d$condition == "mc" | d$condition == "xb")%>% group_by(id) %>% 
  summarise(gbb = mean(gbb_s))

pp <- as_tibble(person_pars)

intercepts <- cbind(s, pp)

ggplot(intercepts, aes(x =gbb, y =Estimate.Intercept   ))+
  geom_point()+
  geom_smooth(method = "lm")+
  theme_classic()
```

Okay, cool. But then we can also model each person's slope, their steepness. And that we can also see if it correlates to gbb


```{r}
#going back to binomial I guess and now adding gbb
#going back to binomial I guess, but calculating slope for each person
individual_slope <- brm(f_cat ~ 1  + (1 +fem|id) , family = bernoulli(link = 'logit'), 
          prior = c(prior(normal(0,3), class = "Intercept"),
                    prior(cauchy(0,3), class = "sd")),
          data = tmp,
          iter = 6000, warmup = 2000,
          chains = 4,
          cores = 4,
          sample_prior = TRUE,
          file = "models/individual_slope"
          )
```

Nice. Now let's start by extracting those parameters

```{r}
person_slope <- ranef(individual_slope)$id %>% 
  as_tibble()

person_slope %>% 
 rownames_to_column() %>%
  arrange(Estimate.fem) %>%
  mutate(id = seq_len(n())) %>%
  ggplot(aes(id, Estimate.fem, ymin = Q2.5.fem, ymax = Q97.5.fem)) + 
    geom_pointrange(alpha = 0.7) +
    coord_flip() + labs(x = "Person Number (Sorted)")+
  theme_classic()
```

Okay, cool. Now let's check it against gender binary beliefs. aaand there doesn't seem to be much there. Cool. I think I can let go of that. But maybe I should also present it. Yes, I should present it. 

```{r}
slope <- cbind(s, person_slope)

ggplot(slope, aes(x =gbb, y =Estimate.fem   ))+
  geom_point()+
  geom_smooth(method = "lm")+
  theme_classic()
```

## But should I add it as a a predictor here too?

```{r, rq2-modelling 2.5, message=FALSE}
tmp$fem_s = tmp$fem - 50
#Main effects model
main_effects_test <- brm(f_cat ~ 1 +fem_s + (1 |id) , family = bernoulli(link = 'logit'), 
          prior = c(prior(normal(0,3), class = "b"),
                    prior(cauchy(0,3), class = "sd")),
          data = tmp,
          iter = 4000, warmup = 1000,
          chains = 4,
          cores = 4,
          sample_prior = TRUE,
          file = "models/mainfx.test"
          )

#Lastly the interaction model
interaction_gbb <- brm(f_cat ~ gbb_s*fem_s  + (1 |id) , family = bernoulli(link = 'logit'), 
         prior = c(prior(normal(0,3), class = "b"),
                   prior(cauchy(0,3), class = "sd")),
          data = tmp,
          iter = 6000, warmup = 2000,
          chains = 4,
          cores = 4,
          sample_prior = TRUE,
          file = "models/interaction_g"
          )


#going back to binomial I guess
main_effects_test <- brm(f_cat ~ 1 + fem_s*condition + (1 +fem_s|id) , family = bernoulli(link = 'logit'), 
          prior = c(prior(normal(0,3), class = "b"),
                    prior(cauchy(0,3), class = "sd")),
          data = tmp,
          iter = 4000, warmup = 1000,
          chains = 4,
          cores = 4,
          sample_prior = TRUE,
          file = "models/mainfx.test2"
          )






get_prior(f_cat ~ 1  + (1 +fem|id) , family = bernoulli(link = 'logit'), data = tmp)



```

## plotting individual item 

let's start by drawing from the posterior

```{r}
#post <- as_draws_df(main_effects_test)
```

